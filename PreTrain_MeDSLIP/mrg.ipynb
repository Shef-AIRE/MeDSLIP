{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import ruamel_yaml as yaml\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import datetime\n",
    "import json\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import utils\n",
    "from scheduler import create_scheduler\n",
    "from optim import create_optimizer\n",
    "from dataset.dataset2 import MedKLIP_Dataset\n",
    "from models.model_MedKLIP import MedKLIP\n",
    "from models.tokenization_bert import BertTokenizer\n",
    "\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokenizer(tokenizer, target_text):\n",
    "\n",
    "    target_tokenizer = tokenizer(\n",
    "        list(target_text),\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=128,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "\n",
    "    return target_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text feature extractor: emilyalsentzer/Bio_ClinicalBERT\n",
      "Image feature extractor: resnet50\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "config = yaml.load(open('configs/Pretrain_MedKLIP.yaml', \"r\"), Loader=yaml.Loader)\n",
    "json_book = json.load(open('data_file/observation explanation.json', \"r\"))\n",
    "disease_book = [json_book[i] for i in json_book]\n",
    "ana_book = [\n",
    "    \"It is located at \" + i\n",
    "    for i in [\n",
    "        \"trachea\",\n",
    "        \"left_hilar\",\n",
    "        \"right_hilar\",\n",
    "        \"hilar_unspec\",\n",
    "        \"left_pleural\",\n",
    "        \"right_pleural\",\n",
    "        \"pleural_unspec\",\n",
    "        \"heart_size\",\n",
    "        \"heart_border\",\n",
    "        \"left_diaphragm\",\n",
    "        \"right_diaphragm\",\n",
    "        \"diaphragm_unspec\",\n",
    "        \"retrocardiac\",\n",
    "        \"lower_left_lobe\",\n",
    "        \"upper_left_lobe\",\n",
    "        \"lower_right_lobe\",\n",
    "        \"middle_right_lobe\",\n",
    "        \"upper_right_lobe\",\n",
    "        \"left_lower_lung\",\n",
    "        \"left_mid_lung\",\n",
    "        \"left_upper_lung\",\n",
    "        \"left_apical_lung\",\n",
    "        \"left_lung_unspec\",\n",
    "        \"right_lower_lung\",\n",
    "        \"right_mid_lung\",\n",
    "        \"right_upper_lung\",\n",
    "        \"right_apical_lung\",\n",
    "        \"right_lung_unspec\",\n",
    "        \"lung_apices\",\n",
    "        \"lung_bases\",\n",
    "        \"left_costophrenic\",\n",
    "        \"right_costophrenic\",\n",
    "        \"costophrenic_unspec\",\n",
    "        \"cardiophrenic_sulcus\",\n",
    "        \"mediastinal\",\n",
    "        \"spine\",\n",
    "        \"clavicle\",\n",
    "        \"rib\",\n",
    "        \"stomach\",\n",
    "        \"right_atrium\",\n",
    "        \"right_ventricle\",\n",
    "        \"aorta\",\n",
    "        \"svc\",\n",
    "        \"interstitium\",\n",
    "        \"parenchymal\",\n",
    "        \"cavoatrial_junction\",\n",
    "        \"cardiopulmonary\",\n",
    "        \"pulmonary\",\n",
    "        \"lung_volumes\",\n",
    "        \"unspecified\",\n",
    "        \"other\",\n",
    "    ]\n",
    "]\n",
    "tokenizer = BertTokenizer.from_pretrained(config[\"text_encoder\"])\n",
    "ana_book_tokenizer = get_tokenizer(tokenizer, ana_book).to(device)\n",
    "disease_book_tokenizer = get_tokenizer(tokenizer, disease_book).to(device)\n",
    "print(\"Creating model\")\n",
    "model = MedKLIP(config, ana_book_tokenizer, disease_book_tokenizer, mode=\"train\")\n",
    "\n",
    "ckpt = torch.load(\"/home/wenrui/Projects/MIMIC/MedKLIP/runs/dual_stream/2024-02-14_22-44-14/checkpoint_64.pth\")\n",
    "model.load_state_dict(ckpt[\"model\"], strict=False)\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_datasets = MedKLIP_Dataset(\n",
    "    '../setting/rad_graph_metric_validate_local.json', '../setting/landmark_observation_adj_mtx.npy', mode=\"train\"\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    val_datasets,\n",
    "    batch_size=1,\n",
    "    num_workers=30,\n",
    "    pin_memory=True,\n",
    "    # sampler=val_sampler,\n",
    "    shuffle=True,\n",
    "    collate_fn=None,\n",
    "    drop_last=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")\n",
    "image = Image.open(\"/home/wenrui/Projects/MIMIC/Data/physionet.org/files/mimic-cxr-jpg/2.0.0/files/p10/p10000032/s50414267/02aa804e-bde0afdd-112c0b34-7bc16630-4e384014.jpg\").convert(\"RGB\")\n",
    "with open(\"/home/wenrui/Projects/MIMIC/CXR_NOTE/p10000032/s50414267.txt\") as f:\n",
    "    text = f.read()\n",
    "    f.close()\n",
    "image = transform(image)\n",
    "image = image.unsqueeze(0).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:tornado.general:SEND Error: Host unreachable\n"
     ]
    }
   ],
   "source": [
    "for i, sample in enumerate(val_dataloader):\n",
    "    print(i)\n",
    "    images = sample[\"image\"].to(device)\n",
    "    labels_e = sample[\"label_e\"].to(device)\n",
    "    labels_p = sample[\"label_p\"].to(device)\n",
    "    index_e = sample[\"index_e\"].to(device)\n",
    "    index_p = sample[\"index_p\"].to(device)\n",
    "    matrix = sample[\"matrix\"].to(device)\n",
    "    text = sample[\"txt\"]\n",
    "    print(text)\n",
    "    loss, x_e, ws_e, x_p, ws_p = model(\n",
    "        images,\n",
    "        labels_e=labels_e,\n",
    "        labels_p=labels_p,\n",
    "        matrix=matrix,\n",
    "        sample_index_e=index_e,\n",
    "        sample_index_p=index_p,\n",
    "        is_train=True,\n",
    "        text_gen=True,\n",
    "        no_cl=config[\"no_cl\"],\n",
    "        exclude_class=config[\"exclude_class\"],\n",
    "    )\n",
    "    # print(output)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = json.load(open('/home/wenrui/Projects/MIMIC/MedKLIP/setting/rad_graph_metric_test_local.json', \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list = list(ann.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'img_path': '/home/wenrui/Projects/MIMIC/physionet.org/files/mimic-cxr-jpg/2.0.0/files/p10/p10032725/s50331901/687754ce-7420bfd3-0a19911f-a27a3916-9019cd53.jpg',\n",
       " 'txt_path': '/home/wenrui/Projects/MIMIC/CXR_NOTE/p10032725/s50331901.txt',\n",
       " 'labels_id': 7892}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann[image_list[0]]#[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "dic = json.load(open('/home/wenrui/Projects/MIMIC/MedKLIP/setting/rad_graph_metric_test_local.json', \"r\"))\n",
    "img_list = list(dic.keys()) \n",
    "no = 0\n",
    "for i in img_list:\n",
    "    txt_path = dic[i][\"txt_path\"]\n",
    "    if not os.path.exists(txt_path):\n",
    "        print(i, txt_path)\n",
    "        no += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4881"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4881"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(img_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
