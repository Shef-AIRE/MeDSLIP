Index: data_check.ipynb
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/data_check.ipynb b/data_check.ipynb
--- a/data_check.ipynb	
+++ b/data_check.ipynb	
@@ -78949,7 +78949,7 @@
     },
     {
       "cell_type": "code",
-      "execution_count": 16,
+      "execution_count": null,
       "metadata": {},
       "outputs": [],
       "source": [
@@ -78961,7 +78961,7 @@
     },
     {
       "cell_type": "code",
-      "execution_count": 15,
+      "execution_count": null,
       "metadata": {},
       "outputs": [
         {
@@ -78981,7 +78981,7 @@
     },
     {
       "cell_type": "code",
-      "execution_count": 17,
+      "execution_count": null,
       "metadata": {},
       "outputs": [],
       "source": [
@@ -78990,7 +78990,7 @@
     },
     {
       "cell_type": "code",
-      "execution_count": 18,
+      "execution_count": null,
       "metadata": {},
       "outputs": [],
       "source": [
@@ -78999,7 +78999,7 @@
     },
     {
       "cell_type": "code",
-      "execution_count": 19,
+      "execution_count": null,
       "metadata": {},
       "outputs": [
         {
@@ -79019,7 +79019,7 @@
     },
     {
       "cell_type": "code",
-      "execution_count": 21,
+      "execution_count": null,
       "metadata": {},
       "outputs": [
         {
@@ -79081,7 +79081,7 @@
     },
     {
       "cell_type": "code",
-      "execution_count": 30,
+      "execution_count": null,
       "metadata": {},
       "outputs": [],
       "source": [
@@ -79092,7 +79092,7 @@
     },
     {
       "cell_type": "code",
-      "execution_count": 31,
+      "execution_count": null,
       "metadata": {},
       "outputs": [
         {
@@ -79112,7 +79112,7 @@
     },
     {
       "cell_type": "code",
-      "execution_count": 32,
+      "execution_count": null,
       "metadata": {},
       "outputs": [],
       "source": [
@@ -79127,7 +79127,7 @@
     },
     {
       "cell_type": "code",
-      "execution_count": 33,
+      "execution_count": null,
       "metadata": {},
       "outputs": [],
       "source": [
@@ -79142,7 +79142,7 @@
     },
     {
       "cell_type": "code",
-      "execution_count": 34,
+      "execution_count": null,
       "metadata": {},
       "outputs": [],
       "source": [
@@ -79151,7 +79151,7 @@
     },
     {
       "cell_type": "code",
-      "execution_count": 38,
+      "execution_count": null,
       "metadata": {},
       "outputs": [
         {
@@ -79171,7 +79171,7 @@
     },
     {
       "cell_type": "code",
-      "execution_count": 4,
+      "execution_count": null,
       "metadata": {},
       "outputs": [
         {
@@ -79194,7 +79194,7 @@
     },
     {
       "cell_type": "code",
-      "execution_count": 1,
+      "execution_count": null,
       "metadata": {},
       "outputs": [
         {
@@ -79216,7 +79216,7 @@
     },
     {
       "cell_type": "code",
-      "execution_count": 6,
+      "execution_count": null,
       "metadata": {},
       "outputs": [
         {
@@ -79239,7 +79239,7 @@
     },
     {
       "cell_type": "code",
-      "execution_count": 7,
+      "execution_count": null,
       "metadata": {},
       "outputs": [
         {
@@ -79269,6 +79269,16 @@
         "        print(a[index[0][i], index[1][i], :])\n",
         "        break"
       ]
+    },
+    {
+      "cell_type": "code",
+      "execution_count": null,
+      "metadata": {},
+      "outputs": [],
+      "source": [
+        "for n, p in self.resnet.named_parameters():\n",
+        "    print(n)"
+      ]
     }
   ],
   "metadata": {
@@ -79278,15 +79288,7 @@
       "name": "python3"
     },
     "language_info": {
-      "codemirror_mode": {
-        "name": "ipython",
-        "version": 3
-      },
-      "file_extension": ".py",
-      "mimetype": "text/x-python",
       "name": "python",
-      "nbconvert_exporter": "python",
-      "pygments_lexer": "ipython3",
       "version": "3.9.18"
     }
   },
Index: PreTrain_MedKLIP/configs/Pretrain_MedKLIP.yaml
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>train_file: 'setting/rad_graph_metric_train_filtered.json'\nvalid_file: 'setting/rad_graph_metric_validate_filtered.json'\ntest_file: 'setting/rad_graph_metric_test_filtered.json'\nlabel_file: 'setting/landmark_observation_adj_mtx.npy'\ndisease_book: 'PreTrain_MedKLIP/data_file/observation explanation.json'\n\nimage_res: 224\npatch_size: 16\nnum_sentences: 12\nnum_tokens: 32\nvision_width: 768\nfea_width: 197\nembed_dim: 256\nbatch_size: 128\ntest_batch_size: 64\ntemp: 0.07\nmlm_probability: 0.15\nqueue_size: 8192\nmomentum: 0.995\nalpha: 0.4\nd_model: 256\nres_base_model: 'resnet50'\nnum_queries: 75\ndropout: 0.1\nattribute_set_size: 2\nN: 4\nH: 4\nno_cl: False\nexclude_class: False\ntext_encoder: 'emilyalsentzer/Bio_ClinicalBERT'\nshuffle_ratio: 0.5\noptimizer: {opt: adamW, lr: 1e-4, weight_decay: 0.02}\nschedular: {sched: cosine, lr: 1e-4, epochs: 100, min_lr: 1e-5, decay_rate: 1, warmup_lr: 1e-5, warmup_epochs: 5, cooldown_epochs: 0}\nnum_neg_samples: 7
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/PreTrain_MedKLIP/configs/Pretrain_MedKLIP.yaml b/PreTrain_MedKLIP/configs/Pretrain_MedKLIP.yaml
--- a/PreTrain_MedKLIP/configs/Pretrain_MedKLIP.yaml	
+++ b/PreTrain_MedKLIP/configs/Pretrain_MedKLIP.yaml	
@@ -1,25 +1,27 @@
-train_file: 'setting/rad_graph_metric_train_filtered.json'
-valid_file: 'setting/rad_graph_metric_validate_filtered.json'
-test_file: 'setting/rad_graph_metric_test_filtered.json'
+train_file: 'setting/rad_graph_metric_train_local.json'
+valid_file: 'setting/rad_graph_metric_validate_local.json'
+test_file: 'setting/rad_graph_metric_test_local.json'
 label_file: 'setting/landmark_observation_adj_mtx.npy'
 disease_book: 'PreTrain_MedKLIP/data_file/observation explanation.json'
 
 image_res: 224
-patch_size: 16
+patch_size: 14
 num_sentences: 12
 num_tokens: 32
 vision_width: 768
 fea_width: 197
 embed_dim: 256
-batch_size: 128
-test_batch_size: 64
+batch_size: 64
+test_batch_size: 32
 temp: 0.07
 mlm_probability: 0.15
 queue_size: 8192
 momentum: 0.995
 alpha: 0.4
 d_model: 256
-res_base_model: 'resnet50'
+vit_encoder: 'base'
+pretrained: True
+reg_tokens: 4
 num_queries: 75
 dropout: 0.1
 attribute_set_size: 2
Index: .idea/workspace.xml
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+><?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project version=\"4\">\n  <component name=\"AutoImportSettings\">\n    <option name=\"autoReloadType\" value=\"SELECTIVE\" />\n  </component>\n  <component name=\"ChangeListManager\">\n    <list default=\"true\" id=\"4f6495d1-14cd-4fdb-8a0a-ea9db950dcf3\" name=\"Changes\" comment=\"\" />\n    <option name=\"SHOW_DIALOG\" value=\"false\" />\n    <option name=\"HIGHLIGHT_CONFLICTS\" value=\"true\" />\n    <option name=\"HIGHLIGHT_NON_ACTIVE_CHANGELIST\" value=\"false\" />\n    <option name=\"LAST_RESOLUTION\" value=\"IGNORE\" />\n  </component>\n  <component name=\"Git.Settings\">\n    <option name=\"RECENT_GIT_ROOT_PATH\" value=\"$PROJECT_DIR$\" />\n  </component>\n  <component name=\"MarkdownSettingsMigration\">\n    <option name=\"stateVersion\" value=\"1\" />\n  </component>\n  <component name=\"ProjectColorInfo\"><![CDATA[{\n  \"associatedIndex\": 2\n}]]></component>\n  <component name=\"ProjectId\" id=\"2bdD9gv5fGUEeSUu6Zov1o7FgC7\" />\n  <component name=\"ProjectViewState\">\n    <option name=\"hideEmptyMiddlePackages\" value=\"true\" />\n    <option name=\"showLibraryContents\" value=\"true\" />\n  </component>\n  <component name=\"PropertiesComponent\"><![CDATA[{\n  \"keyToString\": {\n    \"Python tests.Python tests in test.py.executor\": \"Debug\",\n    \"Python.test.executor\": \"Debug\",\n    \"RunOnceActivity.OpenProjectViewOnStart\": \"true\",\n    \"RunOnceActivity.ShowReadmeOnStart\": \"true\",\n    \"last_opened_file_path\": \"/home/wenrui/Projects/MIMIC/MedKLIP\",\n    \"node.js.detected.package.eslint\": \"true\",\n    \"node.js.detected.package.tslint\": \"true\",\n    \"node.js.selected.package.eslint\": \"(autodetect)\",\n    \"node.js.selected.package.tslint\": \"(autodetect)\",\n    \"nodejs_package_manager_path\": \"npm\",\n    \"settings.editor.selected.configurable\": \"com.jetbrains.python.configuration.PyActiveSdkModuleConfigurable\",\n    \"vue.rearranger.settings.migration\": \"true\"\n  }\n}]]></component>\n  <component name=\"RunManager\" selected=\"Python tests.Python tests in test.py\">\n    <configuration name=\"test\" type=\"PythonConfigurationType\" factoryName=\"Python\" temporary=\"true\" nameIsGenerated=\"true\">\n      <module name=\"MedKLIP\" />\n      <option name=\"ENV_FILES\" value=\"\" />\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\n      <option name=\"PARENT_ENVS\" value=\"true\" />\n      <envs>\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\n      </envs>\n      <option name=\"SDK_HOME\" value=\"\" />\n      <option name=\"WORKING_DIRECTORY\" value=\"$PROJECT_DIR$/Sample_zero-shot_Classification_CXR14\" />\n      <option name=\"IS_MODULE_SDK\" value=\"true\" />\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\n      <EXTENSION ID=\"PythonCoverageRunConfigurationExtension\" runner=\"coverage.py\" />\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/Sample_zero-shot_Classification_CXR14/test.py\" />\n      <option name=\"PARAMETERS\" value=\"\" />\n      <option name=\"SHOW_COMMAND_LINE\" value=\"false\" />\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\n      <option name=\"MODULE_MODE\" value=\"false\" />\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\n      <option name=\"INPUT_FILE\" value=\"\" />\n      <method v=\"2\" />\n    </configuration>\n    <configuration name=\"Python tests in test.py\" type=\"tests\" factoryName=\"Autodetect\" temporary=\"true\" nameIsGenerated=\"true\">\n      <module name=\"MedKLIP\" />\n      <option name=\"ENV_FILES\" value=\"\" />\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\n      <option name=\"PARENT_ENVS\" value=\"true\" />\n      <option name=\"SDK_HOME\" value=\"\" />\n      <option name=\"WORKING_DIRECTORY\" value=\"$PROJECT_DIR$/Sample_zero-shot_Classification_CXR14\" />\n      <option name=\"IS_MODULE_SDK\" value=\"true\" />\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\n      <EXTENSION ID=\"PythonCoverageRunConfigurationExtension\" runner=\"coverage.py\" />\n      <option name=\"_new_additionalArguments\" value=\"&quot;&quot;\" />\n      <option name=\"_new_target\" value=\"&quot;$PROJECT_DIR$/Sample_zero-shot_Classification_CXR14/test.py&quot;\" />\n      <option name=\"_new_targetType\" value=\"&quot;PATH&quot;\" />\n      <method v=\"2\" />\n    </configuration>\n    <recent_temporary>\n      <list>\n        <item itemvalue=\"Python tests.Python tests in test.py\" />\n        <item itemvalue=\"Python.test\" />\n      </list>\n    </recent_temporary>\n  </component>\n  <component name=\"SharedIndexes\">\n    <attachedChunks>\n      <set>\n        <option value=\"bundled-python-sdk-5a2391486177-2887949eec09-com.jetbrains.pycharm.pro.sharedIndexes.bundled-PY-233.13763.11\" />\n      </set>\n    </attachedChunks>\n  </component>\n  <component name=\"SpellCheckerSettings\" RuntimeDictionaries=\"0\" Folders=\"0\" CustomDictionaries=\"0\" DefaultDictionary=\"application-level\" UseSingleDictionary=\"true\" transferred=\"true\" />\n  <component name=\"TaskManager\">\n    <task active=\"true\" id=\"Default\" summary=\"Default task\">\n      <changelist id=\"4f6495d1-14cd-4fdb-8a0a-ea9db950dcf3\" name=\"Changes\" comment=\"\" />\n      <created>1706535912269</created>\n      <option name=\"number\" value=\"Default\" />\n      <option name=\"presentableId\" value=\"Default\" />\n      <updated>1706535912269</updated>\n      <workItem from=\"1706535913349\" duration=\"902000\" />\n    </task>\n    <servers />\n  </component>\n  <component name=\"TypeScriptGeneratedFilesManager\">\n    <option name=\"version\" value=\"3\" />\n  </component>\n  <component name=\"XDebuggerManager\">\n    <breakpoint-manager>\n      <breakpoints>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/Sample_zero-shot_Classification_CXR14/models/model_MedKLIP.py</url>\n          <line>138</line>\n          <option name=\"timeStamp\" value=\"1\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/Sample_zero-shot_Classification_CXR14/models/model_MedKLIP.py</url>\n          <line>137</line>\n          <option name=\"timeStamp\" value=\"2\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/Sample_zero-shot_Classification_CXR14/test.py</url>\n          <line>253</line>\n          <option name=\"timeStamp\" value=\"3\" />\n        </line-breakpoint>\n      </breakpoints>\n    </breakpoint-manager>\n  </component>\n  <component name=\"com.intellij.coverage.CoverageDataManagerImpl\">\n    <SUITE FILE_PATH=\"coverage/MedKLIP$.coverage\" NAME=\" Coverage Results\" MODIFIED=\"1706536164025\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"true\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$/Sample_zero-shot_Classification_CXR14\" />\n    <SUITE FILE_PATH=\"coverage/MedKLIP$test.coverage\" NAME=\"test Coverage Results\" MODIFIED=\"1706536055995\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"true\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$/Sample_zero-shot_Classification_CXR14\" />\n  </component>\n</project>
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/.idea/workspace.xml b/.idea/workspace.xml
--- a/.idea/workspace.xml	
+++ b/.idea/workspace.xml	
@@ -4,7 +4,17 @@
     <option name="autoReloadType" value="SELECTIVE" />
   </component>
   <component name="ChangeListManager">
-    <list default="true" id="4f6495d1-14cd-4fdb-8a0a-ea9db950dcf3" name="Changes" comment="" />
+    <list default="true" id="4f6495d1-14cd-4fdb-8a0a-ea9db950dcf3" name="Changes" comment="">
+      <change beforePath="$PROJECT_DIR$/.idea/MedKLIP.iml" beforeDir="false" afterPath="$PROJECT_DIR$/.idea/MedKLIP.iml" afterDir="false" />
+      <change beforePath="$PROJECT_DIR$/.idea/workspace.xml" beforeDir="false" afterPath="$PROJECT_DIR$/.idea/workspace.xml" afterDir="false" />
+      <change beforePath="$PROJECT_DIR$/PreTrain_MedKLIP/configs/Pretrain_MedKLIP.yaml" beforeDir="false" afterPath="$PROJECT_DIR$/PreTrain_MedKLIP/configs/Pretrain_MedKLIP.yaml" afterDir="false" />
+      <change beforePath="$PROJECT_DIR$/PreTrain_MedKLIP/models/model_MedKLIP.py" beforeDir="false" afterPath="$PROJECT_DIR$/PreTrain_MedKLIP/models/model_MedKLIP.py" afterDir="false" />
+      <change beforePath="$PROJECT_DIR$/PreTrain_MedKLIP/train_MedKLIP.py" beforeDir="false" afterPath="$PROJECT_DIR$/PreTrain_MedKLIP/train_MedKLIP.py" afterDir="false" />
+      <change beforePath="$PROJECT_DIR$/Sample_zero-shot_Classification_CXR14/configs/MedKLIP_config.yaml" beforeDir="false" afterPath="$PROJECT_DIR$/Sample_zero-shot_Classification_CXR14/configs/MedKLIP_config.yaml" afterDir="false" />
+      <change beforePath="$PROJECT_DIR$/Sample_zero-shot_Classification_CXR14/models/model_MedKLIP.py" beforeDir="false" afterPath="$PROJECT_DIR$/Sample_zero-shot_Classification_CXR14/models/model_MedKLIP.py" afterDir="false" />
+      <change beforePath="$PROJECT_DIR$/Sample_zero-shot_Classification_CXR14/test.py" beforeDir="false" afterPath="$PROJECT_DIR$/Sample_zero-shot_Classification_CXR14/test.py" afterDir="false" />
+      <change beforePath="$PROJECT_DIR$/data_check.ipynb" beforeDir="false" afterPath="$PROJECT_DIR$/data_check.ipynb" afterDir="false" />
+    </list>
     <option name="SHOW_DIALOG" value="false" />
     <option name="HIGHLIGHT_CONFLICTS" value="true" />
     <option name="HIGHLIGHT_NON_ACTIVE_CHANGELIST" value="false" />
@@ -16,9 +26,9 @@
   <component name="MarkdownSettingsMigration">
     <option name="stateVersion" value="1" />
   </component>
-  <component name="ProjectColorInfo"><![CDATA[{
-  "associatedIndex": 2
-}]]></component>
+  <component name="ProjectColorInfo">{
+  &quot;associatedIndex&quot;: 2
+}</component>
   <component name="ProjectId" id="2bdD9gv5fGUEeSUu6Zov1o7FgC7" />
   <component name="ProjectViewState">
     <option name="hideEmptyMiddlePackages" value="true" />
@@ -30,6 +40,7 @@
     "Python.test.executor": "Debug",
     "RunOnceActivity.OpenProjectViewOnStart": "true",
     "RunOnceActivity.ShowReadmeOnStart": "true",
+    "git-widget-placeholder": "medklip__vit",
     "last_opened_file_path": "/home/wenrui/Projects/MIMIC/MedKLIP",
     "node.js.detected.package.eslint": "true",
     "node.js.detected.package.tslint": "true",
@@ -40,6 +51,39 @@
     "vue.rearranger.settings.migration": "true"
   }
 }]]></component>
+  <component name="RdControllerToolWindowsLayoutState" isNewUi="true">
+    <layout>
+      <window_info id="Space Code Reviews" show_stripe_button="false" />
+      <window_info id="Bookmarks" show_stripe_button="false" side_tool="true" />
+      <window_info id="Merge Requests" show_stripe_button="false" />
+      <window_info id="Commit_Guest" show_stripe_button="false" />
+      <window_info id="Pull Requests" show_stripe_button="false" />
+      <window_info id="Learn" show_stripe_button="false" />
+      <window_info active="true" content_ui="combo" id="Project" order="0" visible="true" weight="0.14054233" />
+      <window_info id="Commit" order="1" weight="0.25" />
+      <window_info id="Structure" order="2" side_tool="true" weight="0.25" />
+      <window_info anchor="bottom" id="Database Changes" show_stripe_button="false" />
+      <window_info anchor="bottom" id="TypeScript" show_stripe_button="false" />
+      <window_info anchor="bottom" id="TODO" show_stripe_button="false" />
+      <window_info anchor="bottom" id="File Transfer" show_stripe_button="false" />
+      <window_info anchor="bottom" id="Version Control" order="0" />
+      <window_info anchor="bottom" id="Problems" order="1" />
+      <window_info anchor="bottom" id="Problems View" order="2" />
+      <window_info anchor="bottom" id="Terminal" order="3" weight="0.32962963" />
+      <window_info anchor="bottom" id="Services" order="4" weight="0.32962963" />
+      <window_info anchor="bottom" id="Python Packages" order="5" weight="0.32962963" />
+      <window_info anchor="bottom" id="Python Console" order="6" weight="0.32962963" />
+      <window_info anchor="right" id="Endpoints" show_stripe_button="false" />
+      <window_info anchor="right" id="SciView" show_stripe_button="false" />
+      <window_info anchor="right" content_ui="combo" id="Notifications" order="0" weight="0.25" />
+      <window_info anchor="right" id="AIAssistant" order="1" weight="0.32969576" />
+      <window_info anchor="right" id="Database" order="2" weight="0.25" />
+      <window_info anchor="right" id="Gradle" order="3" weight="0.25" />
+      <window_info anchor="right" id="Maven" order="4" weight="0.25" />
+      <window_info active="true" anchor="right" id="Meet New UI" order="4" show_stripe_button="false" weight="0.33035713" />
+      <window_info anchor="right" id="Plots" order="5" weight="0.1" />
+    </layout>
+  </component>
   <component name="RunManager" selected="Python tests.Python tests in test.py">
     <configuration name="test" type="PythonConfigurationType" factoryName="Python" temporary="true" nameIsGenerated="true">
       <module name="MedKLIP" />
@@ -90,7 +134,8 @@
   <component name="SharedIndexes">
     <attachedChunks>
       <set>
-        <option value="bundled-python-sdk-5a2391486177-2887949eec09-com.jetbrains.pycharm.pro.sharedIndexes.bundled-PY-233.13763.11" />
+        <option value="bundled-js-predefined-1d06a55b98c1-e293885f7bc4-JavaScript-PY-241.10840.16" />
+        <option value="bundled-python-sdk-49296595d563-5b69de37365a-com.jetbrains.pycharm.pro.sharedIndexes.bundled-PY-241.10840.16" />
       </set>
     </attachedChunks>
   </component>
@@ -103,6 +148,7 @@
       <option name="presentableId" value="Default" />
       <updated>1706535912269</updated>
       <workItem from="1706535913349" duration="902000" />
+      <workItem from="1707306979616" duration="358000" />
     </task>
     <servers />
   </component>
Index: .idea/MedKLIP.iml
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+><?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<module type=\"PYTHON_MODULE\" version=\"4\">\n  <component name=\"NewModuleRootManager\">\n    <content url=\"file://$MODULE_DIR$\">\n      <excludeFolder url=\"file://$MODULE_DIR$/env\" />\n    </content>\n    <orderEntry type=\"jdk\" jdkName=\"Python 3.9\" jdkType=\"Python SDK\" />\n    <orderEntry type=\"sourceFolder\" forTests=\"false\" />\n  </component>\n  <component name=\"PyDocumentationSettings\">\n    <option name=\"format\" value=\"PLAIN\" />\n    <option name=\"myDocStringFormat\" value=\"Plain\" />\n  </component>\n</module>
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/.idea/MedKLIP.iml b/.idea/MedKLIP.iml
--- a/.idea/MedKLIP.iml	
+++ b/.idea/MedKLIP.iml	
@@ -1,10 +1,8 @@
 <?xml version="1.0" encoding="UTF-8"?>
 <module type="PYTHON_MODULE" version="4">
   <component name="NewModuleRootManager">
-    <content url="file://$MODULE_DIR$">
-      <excludeFolder url="file://$MODULE_DIR$/env" />
-    </content>
-    <orderEntry type="jdk" jdkName="Python 3.9" jdkType="Python SDK" />
+    <content url="file://$MODULE_DIR$" />
+    <orderEntry type="inheritedJdk" />
     <orderEntry type="sourceFolder" forTests="false" />
   </component>
   <component name="PyDocumentationSettings">
Index: PreTrain_MedKLIP/models/model_MedKLIP.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+># modified from https://github.com/tensorflow/models/blob/master/research/slim/nets/s3dg.py\nfrom sklearn.metrics import log_loss\nimport torch.nn as nn\nimport torch\nimport math\nimport numpy as np\nfrom torch.nn.utils.rnn import pad_sequence\nimport torch.nn.functional as F\nfrom .transformer import *\nimport torchvision.models as models\nfrom einops import rearrange\nfrom transformers import AutoModel\nfrom .PosiViT import vit_small_patch16_224 as vit\n\n\"\"\"\nargs.N\nargs.d_model\nargs.res_base_model\nargs.H\nargs.num_queries\nargs.dropout\nargs.attribute_set_size\n\"\"\"\n\n\nclass MedKLIP(nn.Module):\n    def __init__(self, config, ana_book, disease_book, mode=\"train\"):\n        super(MedKLIP, self).__init__()\n\n        self.mode = mode\n        self.d_model = config[\"d_model\"]\n        # ''' book embedding'''\n        with torch.no_grad():\n            bert_model = self._get_bert_basemodel(\n                config[\"text_encoder\"], freeze_layers=None\n            ).to(ana_book[\"input_ids\"].device)\n            self.ana_book = bert_model(\n                input_ids=ana_book[\"input_ids\"],\n                attention_mask=ana_book[\"attention_mask\"],\n            )  # (**encoded_inputs)\n            self.ana_book = self.ana_book.last_hidden_state[:, 0, :]\n            self.disease_book = bert_model(\n                input_ids=disease_book[\"input_ids\"],\n                attention_mask=disease_book[\"attention_mask\"],\n            )  # (**encoded_inputs)\n            self.disease_book = self.disease_book.last_hidden_state[:, 0, :]\n        self.disease_embedding_layer = nn.Linear(768, 256)\n        self.cl_fc = nn.Linear(256, 768)\n\n        self.disease_name = [\n            \"normal\",\n            \"clear\",\n            \"sharp\",\n            \"sharply\",\n            \"unremarkable\",\n            \"intact\",\n            \"stable\",\n            \"free\",\n            \"effusion\",\n            \"opacity\",\n            \"pneumothorax\",\n            \"edema\",\n            \"atelectasis\",\n            \"tube\",\n            \"consolidation\",\n            \"process\",\n            \"abnormality\",\n            \"enlarge\",\n            \"tip\",\n            \"low\",\n            \"pneumonia\",\n            \"line\",\n            \"congestion\",\n            \"catheter\",\n            \"cardiomegaly\",\n            \"fracture\",\n            \"air\",\n            \"tortuous\",\n            \"lead\",\n            \"disease\",\n            \"calcification\",\n            \"prominence\",\n            \"device\",\n            \"engorgement\",\n            \"picc\",\n            \"clip\",\n            \"elevation\",\n            \"expand\",\n            \"nodule\",\n            \"wire\",\n            \"fluid\",\n            \"degenerative\",\n            \"pacemaker\",\n            \"thicken\",\n            \"marking\",\n            \"scar\",\n            \"hyperinflate\",\n            \"blunt\",\n            \"loss\",\n            \"widen\",\n            \"collapse\",\n            \"density\",\n            \"emphysema\",\n            \"aerate\",\n            \"mass\",\n            \"crowd\",\n            \"infiltrate\",\n            \"obscure\",\n            \"deformity\",\n            \"hernia\",\n            \"drainage\",\n            \"distention\",\n            \"shift\",\n            \"stent\",\n            \"pressure\",\n            \"lesion\",\n            \"finding\",\n            \"borderline\",\n            \"hardware\",\n            \"dilation\",\n            \"chf\",\n            \"redistribution\",\n            \"aspiration\",\n            \"tail_abnorm_obs\",\n            \"excluded_obs\",\n        ]\n\n        self.excluded_disease = [\n            \"pneumonia\",\n            \"infiltrate\",\n            \"mass\",\n            \"nodule\",\n            \"emphysema\",\n            \"fibrosis\",\n            \"thicken\",\n            \"hernia\",\n        ]\n\n        self.keep_class_dim = [\n            self.disease_name.index(i)\n            for i in self.disease_name\n            if i not in self.excluded_disease\n        ]\n        \"\"\" visual backbone\"\"\"\n        self.resnet_dict = {\n            \"resnet18\": models.resnet18(weights=None),\n            \"resnet50\": models.resnet50(weights=None),\n        }\n        resnet = vit(reg_tokens=0, pretrained=False, num_classes=768) #self._get_res_basemodel(config[\"res_base_model\"])\n\n        num_ftrs = int(resnet.head.in_features)\n        self.res_features = nn.Sequential(*list(resnet.children())[:-3])\n        # posi_vit = self._get_vit_basemodel(config[\"vit_base_model\"])\n        # self.res_features = posi_vit\n        # num_ftrs = int(posi_vit.embed_dim / 2)\n\n        self.res_l1 = nn.Linear(num_ftrs, num_ftrs)\n        self.res_l2 = nn.Linear(num_ftrs, self.d_model)\n\n        ###################################\n        \"\"\" Query Decoder\"\"\"\n        ###################################\n\n        self.H = config[\"H\"]\n        decoder_layer = TransformerDecoderLayer(\n            self.d_model, config[\"H\"], 1024, 0.1, \"relu\", normalize_before=True\n        )\n        decoder_norm = nn.LayerNorm(self.d_model)\n        self.decoder = TransformerDecoder(\n            decoder_layer, config[\"N\"], decoder_norm, return_intermediate=False\n        )\n\n        # Learnable Queries\n        # self.query_embed = nn.Embedding(config['num_queries'] ,self.d_model)\n        self.dropout_feas = nn.Dropout(config[\"dropout\"])\n\n        # Attribute classifier\n        self.classifier = nn.Linear(self.d_model, config[\"attribute_set_size\"])\n\n        # # Class classifier\n        # self.cls_classifier = nn.Linear(self.d_model,args.num_classes)\n\n        self.apply(self._init_weights)\n\n    def _get_res_basemodel(self, res_model_name):\n        try:\n            res_model = self.resnet_dict[res_model_name]\n            print(\"Image feature extractor:\", res_model_name)\n            return res_model\n        except:\n            raise (\n                \"Invalid model name. Check the config file and pass one of: resnet18 or resnet50\"\n            )\n        \n    def _get_vit_basemodel(self, vit_model_name):\n        try:\n            vit_model = self.vit_dict[vit_model_name]\n            print(\"Image feature extractor:\", vit_model_name)\n            return vit_model\n        except:\n            raise (\n                \"Invalid model name. Check the config file and pass one of: vit_base_patch16, vit_large_patch16 or vit_huge_patch14\"\n            )\n\n    def _get_bert_basemodel(self, bert_model_name, freeze_layers):\n        try:\n            model = AutoModel.from_pretrained(bert_model_name)  # , return_dict=True)\n            print(\"text feature extractor:\", bert_model_name)\n        except:\n            raise (\n                \"Invalid model name. Check the config file and pass a BERT model from transformers lybrary\"\n            )\n\n        if freeze_layers is not None:\n            for layer_idx in freeze_layers:\n                for param in list(model.encoder.layer[layer_idx].parameters()):\n                    param.requires_grad = False\n        return model\n\n    def image_encoder(self, xis):\n        # patch features\n        \"\"\"\n        16 torch.Size([16, 1024, 14, 14])\n        torch.Size([16, 196, 1024])\n        torch.Size([3136, 1024])\n        torch.Size([16, 196, 256])\n        \"\"\"\n        batch_size = xis.shape[0]\n        res_fea = self.res_features(xis)  # batch_size,feature_size,patch_num,patch_num [128, 1024, 14, 14]\n        \n        x = self.res_l1(res_fea) # self.res_l1(h) # [*, 1024] -> [*, 1024]\n        x = F.relu(x)\n\n        x = self.res_l2(x) # self.res_l2(x) # [*, 1024] -> [*, 256]\n        return x\n\n    def forward(\n        self,\n        images,\n        labels,\n        smaple_index=None,\n        is_train=True,\n        no_cl=False,\n        exclude_class=False,\n    ):\n\n        # labels batch,51,75 binary_label batch,75 sample_index batch,index\n        B = images.shape[0]\n        device = images.device\n        \"\"\" Visual Backbone \"\"\"\n        x = self.image_encoder(images)  # batch_size,patch_num,dim [*, 196, 256]\n\n        features = x.transpose(0, 1)  # patch_num b dim [196, *, 256]\n        # query_embed = self.query_embed.weight.unsqueeze(1).repeat(1, B, 1) # query_number, batch, dim\n        query_embed = self.disease_embedding_layer(self.disease_book) # [75, 256]\n        query_embed = query_embed.unsqueeze(1).repeat(1, B, 1) # [75, 128, 256]\n        features, ws = self.decoder(\n            query_embed,\n            features,\n            memory_key_padding_mask=None,\n            pos=None,\n            query_pos=None,\n        ) # [75, 128, 256], list([128, 75, 196])-len=4 \n        # TODO what is ws???\n        out = self.dropout_feas(features) # [75, 128, 256]\n        if is_train == True and no_cl == False:\n            anatomy_query = self.ana_book[\n                smaple_index, :\n            ]  # batch, Q , position_num ,dim [128, 75, 8, 768]\n            # [Q,B,A]\n            ll = out.transpose(0, 1)  # B Q A\n            Q = ll.shape[1]\n            ll = ll.reshape(ll.shape[0] * ll.shape[1], -1)\n            ll = self.cl_fc(ll)\n            ll = ll.unsqueeze(dim=-1)\n            # ll = ll.reshape(B,Q,-1)\n            anatomy_query = anatomy_query.reshape(B * Q, 8, 768) # [9600, 8, 768]\n            ll = torch.bmm(anatomy_query, ll).squeeze()  # B Q position_num [9600, 8]\n            cl_labels = torch.zeros((ll.shape[0])).to(device) # [9600]\n            if exclude_class == True:\n                cl_labels = cl_labels.reshape(B, Q)\n                cl_labels = cl_labels[:, self.keep_class_dim]\n                cl_labels = cl_labels.reshape(-1)\n                ll = ll.reshape(B, Q, -1)\n                ll = ll[:, self.keep_class_dim, :]\n                ll = ll.reshape(B * (len(self.keep_class_dim)), -1)\n\n        x = self.classifier(out).transpose(0, 1)  # B query Atributes [75, 128, 2] -> [128, 75, 2]\n\n        if exclude_class == True:\n            labels = labels[:, self.keep_class_dim] # [128, 75]\n            x = x[:, self.keep_class_dim, :] # torch.Size([128, 75, 2])\n\n        labels = labels.reshape(-1, 1) # [9600, 1]\n        logits = x.reshape(-1, x.shape[-1]) # [9600, 2]\n        Mask = ((labels != -1) & (labels != 2)).squeeze() # [9600]\n\n        cl_mask = (labels == 1).squeeze() # [9600]\n        if is_train == True:\n            labels = labels[Mask].long()\n            logits = logits[Mask]\n            loss_ce = F.cross_entropy(logits, labels[:, 0])\n            if no_cl == False:\n                cl_labels = cl_labels[cl_mask].long()\n                ll = ll[cl_mask]\n                loss_cl = F.cross_entropy(ll, cl_labels)\n                loss = loss_ce + loss_cl\n            else:\n                loss_cl = torch.tensor(0)\n                loss = loss_ce\n        else:\n            loss = 0\n        if is_train == True:\n            return loss, loss_ce, loss_cl\n        else:\n            return loss, x, ws\n\n    @staticmethod\n    def _init_weights(module):\n        r\"\"\"Initialize weights like BERT - N(0.0, 0.02), bias = 0.\"\"\"\n\n        if isinstance(module, nn.Linear):\n            module.weight.data.normal_(mean=0.0, std=0.02)\n\n        elif isinstance(module, nn.MultiheadAttention):\n            module.in_proj_weight.data.normal_(mean=0.0, std=0.02)\n            module.out_proj.weight.data.normal_(mean=0.0, std=0.02)\n\n        elif isinstance(module, nn.Embedding):\n            module.weight.data.normal_(mean=0.0, std=0.02)\n            if module.padding_idx is not None:\n                module.weight.data[module.padding_idx].zero_()\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/PreTrain_MedKLIP/models/model_MedKLIP.py b/PreTrain_MedKLIP/models/model_MedKLIP.py
--- a/PreTrain_MedKLIP/models/model_MedKLIP.py	
+++ b/PreTrain_MedKLIP/models/model_MedKLIP.py	
@@ -10,7 +10,7 @@
 import torchvision.models as models
 from einops import rearrange
 from transformers import AutoModel
-from .PosiViT import vit_small_patch16_224 as vit
+from models import PosiViT #import vit_small_patch16_224 as vit
 
 """
 args.N
@@ -26,7 +26,8 @@
 class MedKLIP(nn.Module):
     def __init__(self, config, ana_book, disease_book, mode="train"):
         super(MedKLIP, self).__init__()
-
+        # image_encoder = 'PosiViT.vit_' + config['vit_encoder'] + '_patch' + str(config['patch_size']) + '_' + str(config['image_res'])
+        vit = PosiViT.vit_base_patch14_reg4_dinov2 # eval(image_encoder)
         self.mode = mode
         self.d_model = config["d_model"]
         # ''' book embedding'''
@@ -142,11 +143,8 @@
             if i not in self.excluded_disease
         ]
         """ visual backbone"""
-        self.resnet_dict = {
-            "resnet18": models.resnet18(weights=None),
-            "resnet50": models.resnet50(weights=None),
-        }
-        resnet = vit(reg_tokens=0, pretrained=False, num_classes=768) #self._get_res_basemodel(config["res_base_model"])
+        
+        resnet = vit(reg_tokens=config['reg_tokens'], pretrained=config['pretrained'], num_classes=768) #self._get_res_basemodel(config["res_base_model"])
 
         num_ftrs = int(resnet.head.in_features)
         self.res_features = nn.Sequential(*list(resnet.children())[:-3])
@@ -225,8 +223,7 @@
         torch.Size([3136, 1024])
         torch.Size([16, 196, 256])
         """
-        batch_size = xis.shape[0]
-        res_fea = self.res_features(xis)  # batch_size,feature_size,patch_num,patch_num [128, 1024, 14, 14]
+        res_fea = self.res_features(xis)[:, 0, :].unsqueeze(1)  # batch_size,feature_size,patch_num,patch_num [128, 1024, 14, 14]
         
         x = self.res_l1(res_fea) # self.res_l1(h) # [*, 1024] -> [*, 1024]
         x = F.relu(x)
@@ -261,7 +258,6 @@
             pos=None,
             query_pos=None,
         ) # [75, 128, 256], list([128, 75, 196])-len=4 
-        # TODO what is ws???
         out = self.dropout_feas(features) # [75, 128, 256]
         if is_train == True and no_cl == False:
             anatomy_query = self.ana_book[
Index: Sample_zero-shot_Classification_CXR14/test.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>import argparse\nimport os\nimport yaml as yaml\nimport numpy as np\nimport random\nimport time\nimport datetime\nimport json\nfrom pathlib import Path\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader\nfrom sklearn.metrics import roc_auc_score, precision_recall_curve, accuracy_score\n\nfrom models.model_MedKLIP import MedKLIP\nfrom dataset.dataset import Chestxray14_Dataset\nfrom models.tokenization_bert import BertTokenizer\n\nchexray14_cls = [\n    \"atelectasis\",\n    \"cardiomegaly\",\n    \"effusion\",\n    \"infiltrate\",\n    \"mass\",\n    \"nodule\",\n    \"pneumonia\",\n    \"pneumothorax\",\n    \"consolidation\",\n    \"edema\",\n    \"emphysema\",\n    \"tail_abnorm_obs\",\n    \"thicken\",\n    \"hernia\",\n]  # Fibrosis seldom appears in MIMIC_CXR and is divided into the 'tail_abnorm_obs' entitiy.\n\noriginal_class = [\n    \"normal\",\n    \"clear\",\n    \"sharp\",\n    \"sharply\",\n    \"unremarkable\",\n    \"intact\",\n    \"stable\",\n    \"free\",\n    \"effusion\",\n    \"opacity\",\n    \"pneumothorax\",\n    \"edema\",\n    \"atelectasis\",\n    \"tube\",\n    \"consolidation\",\n    \"process\",\n    \"abnormality\",\n    \"enlarge\",\n    \"tip\",\n    \"low\",\n    \"pneumonia\",\n    \"line\",\n    \"congestion\",\n    \"catheter\",\n    \"cardiomegaly\",\n    \"fracture\",\n    \"air\",\n    \"tortuous\",\n    \"lead\",\n    \"disease\",\n    \"calcification\",\n    \"prominence\",\n    \"device\",\n    \"engorgement\",\n    \"picc\",\n    \"clip\",\n    \"elevation\",\n    \"expand\",\n    \"nodule\",\n    \"wire\",\n    \"fluid\",\n    \"degenerative\",\n    \"pacemaker\",\n    \"thicken\",\n    \"marking\",\n    \"scar\",\n    \"hyperinflate\",\n    \"blunt\",\n    \"loss\",\n    \"widen\",\n    \"collapse\",\n    \"density\",\n    \"emphysema\",\n    \"aerate\",\n    \"mass\",\n    \"crowd\",\n    \"infiltrate\",\n    \"obscure\",\n    \"deformity\",\n    \"hernia\",\n    \"drainage\",\n    \"distention\",\n    \"shift\",\n    \"stent\",\n    \"pressure\",\n    \"lesion\",\n    \"finding\",\n    \"borderline\",\n    \"hardware\",\n    \"dilation\",\n    \"chf\",\n    \"redistribution\",\n    \"aspiration\",\n    \"tail_abnorm_obs\",\n    \"excluded_obs\",\n]\n\nmapping = []\nfor disease in chexray14_cls:\n    if disease in original_class:\n        mapping.append(original_class.index(disease))\n    else:\n        mapping.append(-1)\nMIMIC_mapping = [_ for i, _ in enumerate(mapping) if _ != -1]\nchexray14_mapping = [i for i, _ in enumerate(mapping) if _ != -1]\ntarget_class = [chexray14_cls[i] for i in chexray14_mapping]\n\n\ndef compute_AUCs(gt, pred, n_class):\n    \"\"\"Computes Area Under the Curve (AUC) from prediction scores.\n    Args:\n        gt: Pytorch tensor on GPU, shape = [n_samples, n_classes]\n          true binary labels.\n        pred: Pytorch tensor on GPU, shape = [n_samples, n_classes]\n          can either be probability estimates of the positive class,\n          confidence values, or binary decisions.\n    Returns:\n        List of AUROCs of all classes.\n    \"\"\"\n    AUROCs = []\n    gt_np = gt.cpu().numpy()\n    pred_np = pred.cpu().numpy()\n    for i in range(n_class):\n        AUROCs.append(roc_auc_score(gt_np[:, i], pred_np[:, i]))\n    return AUROCs\n\n\ndef get_tokenizer(tokenizer, target_text):\n\n    target_tokenizer = tokenizer(\n        list(target_text),\n        padding=\"max_length\",\n        truncation=True,\n        max_length=64,\n        return_tensors=\"pt\",\n    )\n\n    return target_tokenizer\n\n\ndef test(args, config):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    print(\"Total CUDA devices: \", torch.cuda.device_count())\n    torch.set_default_tensor_type(\"torch.FloatTensor\")\n\n    test_dataset = Chestxray14_Dataset(config[\"test_file\"], is_train=False)\n    test_dataloader = DataLoader(\n        test_dataset,\n        batch_size=config[\"test_batch_size\"],\n        num_workers=4,\n        pin_memory=True,\n        sampler=None,\n        shuffle=True,\n        collate_fn=None,\n        drop_last=False,\n    )\n\n    print(\"Creating book\")\n    json_book = json.load(open(config[\"disease_book\"], \"r\"))\n    disease_book = [json_book[i] for i in json_book]\n    tokenizer = BertTokenizer.from_pretrained(config[\"text_encoder\"])\n    disease_book_tokenizer = get_tokenizer(tokenizer, disease_book).to(device)\n\n    print(\"Creating model\")\n    model = MedKLIP(config, disease_book_tokenizer)\n    model = nn.DataParallel(\n        model, device_ids=[i for i in range(torch.cuda.device_count())]\n    )\n    model = model.to(device)\n\n    print(\"Load model from checkpoint:\", args.model_path)\n    checkpoint = torch.load(args.model_path, map_location=\"cpu\")\n    state_dict = checkpoint[\"model\"]\n    model.load_state_dict(state_dict)\n\n    # initialize the ground truth and output tensor\n    gt = torch.FloatTensor()\n    gt = gt.to(device)\n    pred = torch.FloatTensor()\n    pred = pred.to(device)\n\n    print(\"Start testing\")\n    model.eval()\n    for i, sample in enumerate(test_dataloader):\n        image = sample[\"image\"]\n        label = sample[\"label\"][:, chexray14_mapping].float().to(device)\n        gt = torch.cat((gt, label), 0)\n        input_image = image.to(device, non_blocking=True)\n        with torch.no_grad():\n            pred_class = model(input_image)  # batch_size,num_class,dim\n            pred_class = F.softmax(pred_class.reshape(-1, 2)).reshape(\n                -1, len(original_class), 2\n            )\n            pred_class = pred_class[:, MIMIC_mapping, 1]\n            pred = torch.cat((pred, pred_class), 0)\n\n    AUROCs = compute_AUCs(gt, pred, len(target_class))\n    AUROC_avg = np.array(AUROCs).mean()\n    print(\"The average AUROC is {AUROC_avg:.4f}\".format(AUROC_avg=AUROC_avg))\n    for i in range(len(target_class)):\n        print(\"The AUROC of {} is {}\".format(target_class[i], AUROCs[i]))\n    max_f1s = []\n    accs = []\n    for i in range(len(target_class)):\n        gt_np = gt[:, i].cpu().numpy()\n        pred_np = pred[:, i].cpu().numpy()\n        precision, recall, thresholds = precision_recall_curve(gt_np, pred_np)\n        numerator = 2 * recall * precision\n        denom = recall + precision\n        f1_scores = np.divide(\n            numerator, denom, out=np.zeros_like(denom), where=(denom != 0)\n        )\n        max_f1 = np.max(f1_scores)\n        max_f1_thresh = thresholds[np.argmax(f1_scores)]\n        max_f1s.append(max_f1)\n        accs.append(accuracy_score(gt_np, pred_np > max_f1_thresh))\n\n    f1_avg = np.array(max_f1s).mean()\n    acc_avg = np.array(accs).mean()\n    print(\"The average f1 is {F1_avg:.4f}\".format(F1_avg=f1_avg))\n    print(\"The average ACC is {ACC_avg:.4f}\".format(ACC_avg=acc_avg))\n\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\n        \"--config\",\n        default=\"/home/wenrui/Projects/MIMIC/MedKLIP/Sample_zero-shot_Classification_CXR14/configs/MedKLIP_config.yaml\",\n    )\n    parser.add_argument(\n        \"--model_path\",\n        default=\"/home/wenrui/Projects/MIMIC/MedKLIP/runs/12-22-2023/checkpoint_state.pth\",\n    )\n    parser.add_argument(\"--device\", default=\"cuda\")\n    parser.add_argument(\"--gpu\", type=str, default=\"0\", help=\"gpu\")\n    args = parser.parse_args()\n\n    config = yaml.load(open(args.config, \"r\"), Loader=yaml.Loader)\n\n    os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.gpu\n    if args.gpu != \"-1\":\n        torch.cuda.current_device()\n        torch.cuda._initialized = True\n\n    test(args, config)\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/Sample_zero-shot_Classification_CXR14/test.py b/Sample_zero-shot_Classification_CXR14/test.py
--- a/Sample_zero-shot_Classification_CXR14/test.py	
+++ b/Sample_zero-shot_Classification_CXR14/test.py	
@@ -247,7 +247,7 @@
     )
     parser.add_argument(
         "--model_path",
-        default="/home/wenrui/Projects/MIMIC/MedKLIP/runs/12-22-2023/checkpoint_state.pth",
+        default="/home/wenrui/Projects/MIMIC/MedKLIP/runs/medklip_vit/2024-02-07_08-34-05/checkpoint_state.pth",
     )
     parser.add_argument("--device", default="cuda")
     parser.add_argument("--gpu", type=str, default="0", help="gpu")
Index: PreTrain_MedKLIP/train_MedKLIP.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>import argparse\nimport os\nimport ruamel_yaml as yaml\nimport numpy as np\nimport random\nimport time\nimport datetime\nimport json\nfrom pathlib import Path\n\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\nimport torch.backends.cudnn as cudnn\n\nfrom tensorboardX import SummaryWriter\n\nimport utils\nfrom scheduler import create_scheduler\nfrom optim import create_optimizer\nfrom dataset.dataset import MedKLIP_Dataset\nfrom models.model_MedKLIP import MedKLIP\nfrom models.tokenization_bert import BertTokenizer\n\nfrom tqdm import tqdm\n\n\ndef get_tokenizer(tokenizer, target_text):\n\n    target_tokenizer = tokenizer(\n        list(target_text),\n        padding=\"max_length\",\n        truncation=True,\n        max_length=128,\n        return_tensors=\"pt\",\n    )\n\n    return target_tokenizer\n\n\ndef train(\n    model,\n    data_loader,\n    optimizer,\n    epoch,\n    warmup_steps,\n    device,\n    scheduler,\n    args,\n    config,\n    writer,\n):\n    model.train()\n    metric_logger = utils.MetricLogger(delimiter=\"  \")\n    metric_logger.add_meter(\n        \"lr\", utils.SmoothedValue(window_size=50, fmt=\"{value:.6f}\")\n    )\n    metric_logger.add_meter(\n        \"loss\", utils.SmoothedValue(window_size=50, fmt=\"{value:.6f}\")\n    )\n    metric_logger.add_meter(\n        \"loss_ce\", utils.SmoothedValue(window_size=50, fmt=\"{value:.6f}\")\n    )\n    metric_logger.add_meter(\n        \"loss_cl\", utils.SmoothedValue(window_size=50, fmt=\"{value:.6f}\")\n    )\n    metric_logger.update(loss=1.0)\n    metric_logger.update(loss_ce=1.0)\n    metric_logger.update(loss_cl=1.0)\n    metric_logger.update(lr=scheduler._get_lr(epoch)[0])\n\n    header = \"Train Epoch: [{}]\".format(epoch)\n    print_freq = 1\n    step_size = 100\n    warmup_iterations = warmup_steps * step_size\n    scalar_step = epoch * len(data_loader)\n\n    for i, sample in enumerate(\n        metric_logger.log_every(data_loader, print_freq, header)\n    ):\n\n        images = sample[\"image\"].to(device) # [Batch, 3, 224, 224]\n        labels = sample[\"label\"].to(device) # [Batch, Disease]\n        index = sample[\"index\"].to(device) # [Batch, Disease, Position]\n\n        optimizer.zero_grad()\n\n        loss, loss_ce, loss_cl = model(\n            images,\n            labels,\n            index,\n            is_train=True,\n            no_cl=config[\"no_cl\"],\n            exclude_class=config[\"exclude_class\"],\n        )\n        loss.backward()\n        optimizer.step()\n        writer.add_scalar(\"loss/loss\", loss, scalar_step)\n        writer.add_scalar(\"loss/loss_ce\", loss_ce, scalar_step)\n        writer.add_scalar(\"loss/loss_cl\", loss_cl, scalar_step)\n        scalar_step += 1\n        metric_logger.update(loss_ce=loss_ce.item())\n        metric_logger.update(loss=loss.item())\n        metric_logger.update(loss_cl=loss_cl.item())\n        if epoch == 0 and i % step_size == 0 and i <= warmup_iterations:\n            scheduler.step(i // step_size)\n        metric_logger.update(lr=scheduler._get_lr(epoch)[0])\n\n    # gather the stats from all processes\n    metric_logger.synchronize_between_processes()\n    print(\"Averaged stats:\", metric_logger.global_avg())\n    return {\n        k: \"{:.3f}\".format(meter.global_avg)\n        for k, meter in metric_logger.meters.items()\n    }  # ,loss_epoch.mean()\n\n\ndef valid(model, data_loader, epoch, device, config, writer):\n    model.eval()\n    temp = nn.Parameter(torch.ones([]) * config[\"temp\"])\n    val_scalar_step = epoch * len(data_loader)\n    val_loss = []\n    for i, sample in enumerate(data_loader):\n\n        images = sample[\"image\"].to(device)\n        labels = sample[\"label\"].to(device)\n        index = sample[\"index\"].to(device)\n\n        with torch.no_grad():\n            loss, loss_ce, loss_cl = model(\n                images,\n                labels,\n                index,\n                is_train=True,\n                no_cl=config[\"no_cl\"],\n                exclude_class=config[\"exclude_class\"],\n            )\n            val_loss.append(loss.item())\n            writer.add_scalar(\"val_loss/loss\", loss, val_scalar_step)\n            writer.add_scalar(\"val_loss/loss_ce\", loss_ce, val_scalar_step)\n            writer.add_scalar(\"val_loss/loss_cl\", loss_cl, val_scalar_step)\n            val_scalar_step += 1\n    avg_val_loss = np.array(val_loss).mean()\n    return avg_val_loss\n\n\ndef main(args, config):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    print(\"Total CUDA devices: \", torch.cuda.device_count())\n    torch.set_default_tensor_type(\"torch.FloatTensor\")\n    cudnn.benchmark = True\n\n    start_epoch = 0\n    max_epoch = config[\"schedular\"][\"epochs\"]\n    warmup_steps = config[\"schedular\"][\"warmup_epochs\"]\n\n    #### Dataset ####\n    print(\"Creating dataset\")\n    train_datasets = MedKLIP_Dataset(\n        config[\"train_file\"], config[\"label_file\"], mode=\"train\"\n    )\n    train_dataloader = DataLoader(\n        train_datasets,\n        batch_size=config[\"batch_size\"],\n        num_workers=4,\n        pin_memory=True,\n        sampler=None,\n        shuffle=True,\n        collate_fn=None,\n        drop_last=True,\n    )\n\n    val_datasets = MedKLIP_Dataset(\n        config[\"valid_file\"], config[\"label_file\"], mode=\"train\"\n    )\n    val_dataloader = DataLoader(\n        val_datasets,\n        batch_size=config[\"batch_size\"],\n        num_workers=4,\n        pin_memory=True,\n        sampler=None,\n        shuffle=True,\n        collate_fn=None,\n        drop_last=True,\n    )\n\n    print(\"Creating book\")\n    json_book = json.load(open(config[\"disease_book\"], \"r\"))\n    disease_book = [json_book[i] for i in json_book]\n    ana_book = [\n        \"It is located at \" + i\n        for i in [\n            \"trachea\",\n            \"left_hilar\",\n            \"right_hilar\",\n            \"hilar_unspec\",\n            \"left_pleural\",\n            \"right_pleural\",\n            \"pleural_unspec\",\n            \"heart_size\",\n            \"heart_border\",\n            \"left_diaphragm\",\n            \"right_diaphragm\",\n            \"diaphragm_unspec\",\n            \"retrocardiac\",\n            \"lower_left_lobe\",\n            \"upper_left_lobe\",\n            \"lower_right_lobe\",\n            \"middle_right_lobe\",\n            \"upper_right_lobe\",\n            \"left_lower_lung\",\n            \"left_mid_lung\",\n            \"left_upper_lung\",\n            \"left_apical_lung\",\n            \"left_lung_unspec\",\n            \"right_lower_lung\",\n            \"right_mid_lung\",\n            \"right_upper_lung\",\n            \"right_apical_lung\",\n            \"right_lung_unspec\",\n            \"lung_apices\",\n            \"lung_bases\",\n            \"left_costophrenic\",\n            \"right_costophrenic\",\n            \"costophrenic_unspec\",\n            \"cardiophrenic_sulcus\",\n            \"mediastinal\",\n            \"spine\",\n            \"clavicle\",\n            \"rib\",\n            \"stomach\",\n            \"right_atrium\",\n            \"right_ventricle\",\n            \"aorta\",\n            \"svc\",\n            \"interstitium\",\n            \"parenchymal\",\n            \"cavoatrial_junction\",\n            \"cardiopulmonary\",\n            \"pulmonary\",\n            \"lung_volumes\",\n            \"unspecified\",\n            \"other\",\n        ]\n    ]\n    tokenizer = BertTokenizer.from_pretrained(config[\"text_encoder\"])\n    ana_book_tokenizer = get_tokenizer(tokenizer, ana_book).to(device)\n    disease_book_tokenizer = get_tokenizer(tokenizer, disease_book).to(device)\n    print(\"Creating model\")\n    model = MedKLIP(config, ana_book_tokenizer, disease_book_tokenizer, mode=\"train\")\n    model = nn.DataParallel(\n        model, device_ids=[i for i in range(torch.cuda.device_count())]\n    )\n    model = model.to(device)\n\n    arg_opt = utils.AttrDict(config[\"optimizer\"])\n    optimizer = create_optimizer(arg_opt, model)\n    arg_sche = utils.AttrDict(config[\"schedular\"])\n    lr_scheduler, _ = create_scheduler(arg_sche, optimizer)\n\n    if args.checkpoint:\n        checkpoint = torch.load(args.checkpoint, map_location=\"cpu\")\n        state_dict = checkpoint[\"model\"]\n        optimizer.load_state_dict(checkpoint[\"optimizer\"])\n        lr_scheduler.load_state_dict(checkpoint[\"lr_scheduler\"])\n        start_epoch = checkpoint[\"epoch\"] + 1\n        model.load_state_dict(state_dict)\n        print(\"load checkpoint from %s\" % args.checkpoint)\n\n    print(\"Start training\")\n    start_time = time.time()\n\n    writer = SummaryWriter(os.path.join(args.output_dir, \"log\"))\n    for epoch in range(start_epoch, max_epoch):\n        if epoch > 0:\n            lr_scheduler.step(epoch + warmup_steps)\n        train_stats = train(\n            model,\n            train_dataloader,\n            optimizer,\n            epoch,\n            warmup_steps,\n            device,\n            lr_scheduler,\n            args,\n            config,\n            writer,\n        )\n\n        for k, v in train_stats.items():\n            train_loss_epoch = v\n\n        writer.add_scalar(\"loss/train_loss_epoch\", float(train_loss_epoch), epoch)\n        writer.add_scalar(\"loss/leaning_rate\", lr_scheduler._get_lr(epoch)[0], epoch)\n\n        val_loss = valid(model, val_dataloader, epoch, device, config, writer)\n        writer.add_scalar(\"loss/val_loss_epoch\", val_loss, epoch)\n\n        if utils.is_main_process():\n            log_stats = {\n                **{f\"train_{k}\": v for k, v in train_stats.items()},\n                \"epoch\": epoch,\n                \"val_loss\": val_loss.item(),\n            }\n            save_obj = {\n                \"model\": model.state_dict(),\n                \"optimizer\": optimizer.state_dict(),\n                \"lr_scheduler\": lr_scheduler.state_dict(),\n                \"config\": config,\n                \"epoch\": epoch,\n            }\n            torch.save(save_obj, os.path.join(args.output_dir, \"checkpoint_state.pth\"))\n\n            with open(os.path.join(args.output_dir, \"log.txt\"), \"a\") as f:\n                f.write(json.dumps(log_stats) + \"\\n\")\n\n        if epoch % 20 == 1 and epoch > 1:\n            save_obj = {\n                \"model\": model.state_dict(),\n                \"optimizer\": optimizer.state_dict(),\n                \"lr_scheduler\": lr_scheduler.state_dict(),\n                \"config\": config,\n                \"epoch\": epoch,\n            }\n            torch.save(\n                save_obj,\n                os.path.join(args.output_dir, \"checkpoint_\" + str(epoch) + \".pth\"),\n            )\n\n    total_time = time.time() - start_time\n    total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n    print(\"Training time {}\".format(total_time_str))\n\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\n        \"--config\", default=\"PreTrain_MedKLIP/configs/Pretrain_MedKLIP.yaml\"\n    )\n    parser.add_argument(\"--checkpoint\", default=\"\")\n    parser.add_argument(\"--output_dir\", default=\"runs/medklip_vit\")\n    parser.add_argument(\"--device\", default=\"cuda\")\n    parser.add_argument(\"--gpu\", type=str, default=\"0\", help=\"gpu\")\n    args = parser.parse_args()\n    import datetime\n    args.output_dir = os.path.join(\n        args.output_dir, datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n    )\n\n    config = yaml.load(open(args.config, \"r\"), Loader=yaml.Loader)\n\n    Path(args.output_dir).mkdir(parents=True, exist_ok=True)\n\n    yaml.dump(config, open(os.path.join(args.output_dir, \"config.yaml\"), \"w\"))\n\n    os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.gpu\n    if args.gpu != \"-1\":\n        torch.cuda.current_device()\n        torch.cuda._initialized = True\n\n    main(args, config)
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/PreTrain_MedKLIP/train_MedKLIP.py b/PreTrain_MedKLIP/train_MedKLIP.py
--- a/PreTrain_MedKLIP/train_MedKLIP.py	
+++ b/PreTrain_MedKLIP/train_MedKLIP.py	
@@ -163,7 +163,7 @@
     train_dataloader = DataLoader(
         train_datasets,
         batch_size=config["batch_size"],
-        num_workers=4,
+        num_workers=30,
         pin_memory=True,
         sampler=None,
         shuffle=True,
@@ -177,7 +177,7 @@
     val_dataloader = DataLoader(
         val_datasets,
         batch_size=config["batch_size"],
-        num_workers=4,
+        num_workers=30,
         pin_memory=True,
         sampler=None,
         shuffle=True,
Index: Sample_zero-shot_Classification_CXR14/configs/MedKLIP_config.yaml
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>test_file: '/home/wenrui/Projects/MIMIC/MedKLIP/Sample_zero-shot_Classification_CXR14/data/miccai2023_nih-cxr-lt_labels_all.csv'\ndisease_book: '/home/wenrui/Projects/MIMIC/MedKLIP/Sample_zero-shot_Classification_CXR14/observation explanation.json'\n\nimage_res: 224\ntest_batch_size: 64\n\nd_model: 256\nres_base_model: 'resnet50'\nnum_queries: 75\ndropout: 0.1\nattribute_set_size: 2\nN: 4\nH: 4\ntext_encoder: 'emilyalsentzer/Bio_ClinicalBERT'\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/Sample_zero-shot_Classification_CXR14/configs/MedKLIP_config.yaml b/Sample_zero-shot_Classification_CXR14/configs/MedKLIP_config.yaml
--- a/Sample_zero-shot_Classification_CXR14/configs/MedKLIP_config.yaml	
+++ b/Sample_zero-shot_Classification_CXR14/configs/MedKLIP_config.yaml	
@@ -5,8 +5,9 @@
 test_batch_size: 64
 
 d_model: 256
-res_base_model: 'resnet50'
+vit_encoder: 'base'
 num_queries: 75
+patch_size: 16
 dropout: 0.1
 attribute_set_size: 2
 N: 4
